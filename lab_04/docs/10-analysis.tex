\section*{Задание}

Разработать программу, которая предоставляет возможность моделирования работы системы, состоящей из генератора сообщений (выдает сообщения по равномерному закону), буферной памяти (работающей по принципу FIFO), обслуживающего аппарата (обрабатывает сообщения по закону Пуассона). С определенной вероятностью (задается пользователем) часть обработанных сообщений снова поступает в очередь. Найти минимальный объем очереди (размер буферной памяти), при котором сообщения не будут теряться.
Использовать 2 принципа протяжки модельного времени --- $\Delta{t}$ и событийный. Для ввода параметров модели необходимо реализовать графический интерфейс.

\section*{Теоретические сведения}
\textbf{Используемые законы распределения}

\textbf{Равномерное распределение}

Функция плотности распределения $f(x)$ случайной величины $X$, имеющей равномерное распределение на отрезке $[a, b]$ ($X \sim R(a, b)$), где $a, b \in R$, имеет следующий вид:
\begin{equation}
	f(x)=\begin{cases}
		\frac{1}{b - a}, & x \in [a, b] \\
		0, & \text{иначе}.
	\end{cases}
\end{equation}

Соответствующая функция распределения $F(x) = \int_{-\infty}^{x}f(t)dt$ принимает вид: 
\begin{equation}
	F(x)=\begin{cases}
		0, & x < a \\
		\frac{x - a}{b - a}, & x \in [a, b] \\
		1, & x > b.
	\end{cases}
\end{equation}

Момент времени $t_i$ может быть вычислен по следующей формуле:

\begin{equation}
    t_i = a + (b - a) R, 
\end{equation}

где $R \in [0, 1]$ --- равномерно распределенная случайная величина в
промежутке~$[0, 1]$.

\textbf{Распределение Пуассона}

Дискретная случайная величина $X$ имеет закон распределения Пуассона с параметром $\lambda$ ($X \sim \Pi(\lambda)$), где $\lambda > 0$, если она принимает значения $0, 1, 2,...$ с вероятностями:

\begin{equation}
	P(X = k)= e^{-\lambda}\frac{\lambda^{k}}{k!}, \quad k \in \{0, 1, 2, ...\}
\end{equation}

Соответствующая функция распределения принимает вид:

\begin{equation}
	F(x) = e^{-\lambda}\sum_{k=0}^{x-1}\frac{\lambda^{k}}{k!} 
\end{equation}

Для генерации Пуассоновских переменных можно использовать метод точек, в основе
которого лежит генерируемое случайное значение $R_i$, равномерно распределенное на
[0, 1], до тех пор, пока не станет справедливым:
\begin{equation}
	\sum_{i=0}^{x}{R_i} >= e^{-\lambda} > \sum_{i=0}^{x + 1}{R_i}
\end{equation}

\textbf{Принципы протяжки модельного времени}

\textbf{Принцип $\Delta t$}

Пошаговый принцип или принцип $\Delta t$ заключается в последовательном анализе
состояний всех блоков в момент времени $t + \Delta t$ по заданному состоянию
блоков в момент времени $t$. При этом новое состояние блоков определяется в
соответствии с их алгоритмическим описанием с учетом действующих случайных
факторов. В результате этого анализа принимается решение о том, какие
общесистемные события должны имитироваться программой на данный момент времени.

Основной недостаток принципа $\Delta t$ заключается в значительных затратах
вычислительных ресурсов, а при недостаточно малом $\Delta t$ появляется
опасность пропуска отдельных событий в системе, исключающая возможность
получения правильных результатов при моделировании.

\textbf{Событийный принцип}

Характерное свойство систем обработки информации то, что состояния отдельных устройств изменяются в дискретные моменты времени,
совпадающие с моментами поступления сообщений в систему, окончания выполнения
задания и т.п., поэтому моделирование и продвижение текущего времени в системе удобно
проводить, используя событийный принцип.

При использовании данного принципа состояние всех блоков имитационной модели
анализируется лишь в момент появления какого-либо события. Момент наступления
следующего события определяется минимальными значениями из списка будущих
событий, представляющего собой совокупность моментов ближайшего изменения состояния каждого из блоков
системы.

